mainly it's estimator and then transformer . 
It's a series and  combination of those . 
trasnformer is an algorithm which takes dataframe as a parameter in i'ts fit method and produces a model . 

that model when applided on the dataframe products anotehr dataframe , whic is a predicted dtatframe with appended column / label which is the predicted column . This step is transformation . 

parameters , estimators and and transfsformers have parameters . 
like LR has setIterator(10) values so it iterates 10 tiiems before producing a model .

models are saved on hard disck using save methods . 

https://spark.apache.org/docs/latest/ml-pipeline.html#properties-of-pipeline-components 

further read the model and it's examples from this page . aboev page . 

spark streaming model deployment is pending 
spark mlib code sample is pending 
different algos read is pending 


----------------------------------


ROLES & RESPONSIBILITIES:

• Build technology stack for AI/ML use cases from concept to production deployment
• Build data pipelines, ingestion of structured & structured data for model training
• Create Generative AI pipelines & technology stack e.g., orchestration, prompt engineering,
fine tuning etc.
• Deploy AI/ML models into production and build API layer for application integration


CAPABILITIES:

• Very high proficiency in Python programming language, knowledge of other languages
such as R, Java would be a plus.
• Knowledge of various AI/ML models including deep learning models
• Knowledge of Generative AI stack – Large Language Models / Foundation Models, vector
databases, orchestration stack
• Hand on experience in building AI orchestration with frameworks like LangChain.
• Knowledge of vector databases e.g., Pinecone, Chroma etc.
• Deep understanding of data processing frameworks e.g., Data Bricks, Airflow etc.
• Knowledge of API frameworks Django, Flask etc.
• Understanding of cloud data & AI stack on AWS / Azure / GCP is preferred
